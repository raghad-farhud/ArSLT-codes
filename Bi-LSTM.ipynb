{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-OS and NumPy: For file and numerical operations.                                                              2-PyTorch Modules (torch, nn, optim, etc.): For building and\n",
    " training the neural network.\n",
    "3-Scikit-learn Modules: For data splitting and evaluation metrics.\n",
    "4-TensorFlow Keras: Specifically to_categorical for one-hot encoding labels.\n",
    "5-Matplotlib and Seaborn: For plotting and visualizing data and results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define the data path and action labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = 'F:/NEWAI/sign language/Data_MP/'  # Path to dataset\n",
    "actions = [\n",
    "    \"can_you_help_me\", \"doesnt_matter\", \"good_bey\", \"i_have_to_go\",\n",
    "    \"i_think_you_are_wrong\", \"sorry_cant_stay\", \"sorry_for_being_late\",\n",
    "    \"speak_slowly\", \"thanks_for_your_concern\", \"wish_you_luck_in_work\",\n",
    "    \"wish_you_good_journey\", \"wish_you_good_vacation\", \"please_quickly\",\n",
    "    \"explain_again\", \"repeat_again\", \"free_or_busy\", \"happy_to_know_you\",\n",
    "    \"i_disagree\", \"i_agree\", \"i_would_like_to_meet_you\", \"any_service\",\n",
    "    \"come_quickly\", \"happy_new_year\", \"how_can_i_call_you\", \"wait_please\",\n",
    "    \"lets_go_swim\", \"whats_your_name\", \"what_about_going_for_a_walk\",\n",
    "    \"unbelievable\", \"can_i_take_from_your_time\"\n",
    "]\n",
    "sequence_length = 120  # Assuming each video is 4 seconds at 30 fps\n",
    "\n",
    "# Create a label map that assigns each action a unique index\n",
    "label_map = {action: i for i, action in enumerate(actions)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1-DATA_PATH: Specifies where the dataset is stored.\n",
    "2-actions: A list of all the sign language actions (classes) that the model will recognize.\n",
    "3-sequence_length: Defines the fixed length for each input sequence (e.g., number of frames)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4-label_map: A dictionary that maps each action label to a unique integer index. This is essential for converting categorical labels into numerical form suitable for model training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing:\n",
    "This block defines the function for padding or truncating sequences and loads the dataset from the file path. It also processes and prepares the data for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to pad or truncate sequences\n",
    "def pad_or_truncate(sequence, max_len):\n",
    "    \"\"\"Pad or truncate the sequence to ensure uniform length.\"\"\"\n",
    "    if len(sequence) < max_len:\n",
    "        padding = np.zeros((max_len - sequence.shape[0], sequence.shape[1]))\n",
    "        return np.vstack((sequence, padding))\n",
    "    else:\n",
    "        return sequence[:max_len]\n",
    "\n",
    "# Initialize empty lists to hold sequences and labels\n",
    "sequences, labels = [], []\n",
    "\n",
    "# Load all sequences and labels based on the folder names\n",
    "for action in actions:\n",
    "    action_path = os.path.join(DATA_PATH, action)  # Path to each action folder\n",
    "    if not os.path.exists(action_path):\n",
    "        print(f\"Directory not found: {action_path}. Skipping this action.\")\n",
    "        continue\n",
    "\n",
    "    # Iterate over all files in the action folder\n",
    "    for video in os.listdir(action_path):\n",
    "        if video.endswith(\"_sequence.npy\"):  # Ensure it's a sequence file\n",
    "            video_path = os.path.join(action_path, video)\n",
    "            try:\n",
    "                # Load the sequence and adjust its length\n",
    "                sequence = np.load(video_path)\n",
    "                sequence = pad_or_truncate(sequence, sequence_length)\n",
    "                sequences.append(sequence)\n",
    "                labels.append(label_map[action])  # Add the label based on the folder name\n",
    "            except Exception as e:\n",
    "                print(f\"Error loading file {video_path}: {e}\")\n",
    "\n",
    "# Check if any data was loaded\n",
    "if not sequences or not labels:\n",
    "    print(\"No data loaded. Please check the dataset paths and file availability.\")\n",
    "    exit()\n",
    "\n",
    "# Convert sequences and labels to numpy arrays\n",
    "X = np.array(sequences)\n",
    "y = to_categorical(labels).astype(int)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pad_or_truncate: Ensures that each video sequence is of the same length by either padding shorter sequences with zeros or truncating longer ones. This is important because neural networks require inputs of uniform length for batch processing.\n",
    "#####################################################################################################################################################\n",
    "1-sequences, labels: Lists that will store the processed video sequences and their corresponding labels.\n",
    "2-os.path.join: Joins the DATA_PATH and each action to create the full path for each action folder.\n",
    "3-os.listdir: Lists all the files in the folder corresponding to each action.\n",
    "4-np.load: Loads the .npy file, which contains the pre-processed video sequence.\n",
    "5-sequence = pad_or_truncate: Ensures that the sequence has a fixed length.\n",
    "6-labels.append: Adds the corresponding action label based on the folder name to the labels list.\n",
    "#######################################################################################################\n",
    "1-X and y: Convert the lists of sequences and labels into numpy arrays, where X holds the video data and y holds the one-hot encoded labels.\n",
    "2-to_categorical: Converts the integer labels into one-hot encoded format (needed for classification tasks).\n",
    "3-train_test_split: Splits the data into training and testing sets. 80% is used for training and 20% for testing.\n",
    "################################################################################################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Dataset and DataLoader Definition\n",
    "This block defines a custom PyTorch dataset class and creates DataLoader objects for both training and testing datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for PyTorch\n",
    "class KeypointsToTextDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Create DataLoaders for training and testing\n",
    "train_dataset = KeypointsToTextDataset(torch.tensor(X_train, dtype=torch.float32),\n",
    "                                       torch.tensor(np.argmax(y_train, axis=1), dtype=torch.long))\n",
    "test_dataset = KeypointsToTextDataset(torch.tensor(X_test, dtype=torch.float32),\n",
    "                                      torch.tensor(np.argmax(y_test, axis=1), dtype=torch.long))\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KeypointsToTextDataset: A custom PyTorch dataset class. It allows easy loading and batching of sequences (features) and their labels during training and testing. The __len__ function returns the total number of samples, and the __getitem__ function returns the feature and label for a given index.########################################################################################\n",
    "DataLoader: A PyTorch object that splits the dataset into batches. The train_loader will randomly shuffle the data to avoid overfitting, while the test_loader will not shuffle the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Definition (Enhanced Bi-LSTM with Attention)\n",
    "This block defines the model architecture, including a Bi-directional LSTM with an Attention mechanism and a fully connected layer for classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the enhanced RNN with Bi-directional LSTM and Attention mechanism\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Attention, self).__init__()\n",
    "        self.attn = nn.Linear(hidden_dim, 1)\n",
    "\n",
    "    def forward(self, lstm_output):\n",
    "        attn_weights = torch.tanh(self.attn(lstm_output))\n",
    "        attn_weights = torch.softmax(attn_weights, dim=1)\n",
    "        context = torch.bmm(attn_weights.transpose(1, 2), lstm_output)\n",
    "        return context.squeeze(1), attn_weights\n",
    "\n",
    "class EnhancedRNNBiLSTMModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_classes, dropout_rate=0.3):\n",
    "        super(EnhancedRNNBiLSTMModel, self).__init__() \n",
    "        self.rnn = nn.RNN(input_dim, hidden_dim, batch_first=True)\n",
    "        self.bilstm = nn.LSTM(hidden_dim, hidden_dim, batch_first=True, bidirectional=True)\n",
    "        self.attention = Attention(hidden_dim * 2)\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        rnn_out, _ = self.rnn(x)\n",
    "        lstm_out, _ = self.bilstm(rnn_out)\n",
    "        context, attn_weights = self.attention(lstm_out)\n",
    "        context = self.dropout(context)\n",
    "        output = self.fc(context)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Attention Mechanism: The attention layer is designed to focus on the most important frames in a sequence. It calculates a set of attention weights for each time step and applies them to the LSTM output. The resulting context vector highlights the most significant parts of the sequence.#############################################################################################\n",
    "EnhancedRNNBiLSTMModel:\n",
    "1-The model starts with a simple RNN layer, followed by a Bi-directional LSTM.\n",
    "2-BiLSTM: Captures both forward and backward context in sequences, which helps in understanding dependencies in time-series data like video frames.\n",
    "3-Attention: Highlights the most important frames within the sequence.\n",
    "4-Dropout: Adds regularization to reduce overfitting.\n",
    "5-Fully Connected Layer: Maps the LSTM's output to the final class probabilities for each sign language action.\n",
    "##########################################################################################3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Training and Evaluation Setup\n",
    "This block defines the functions for training and evaluating the model. It uses the AdamW optimizer, CrossEntropyLoss, and tracks loss during training. The evaluation function calculates accuracy, classification report, and confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30, Loss: 2.7522\n",
      "Epoch 2/30, Loss: 2.2006\n",
      "Epoch 3/30, Loss: 1.7888\n",
      "Epoch 4/30, Loss: 1.3983\n",
      "Epoch 5/30, Loss: 1.0988\n",
      "Epoch 6/30, Loss: 0.9746\n",
      "Epoch 7/30, Loss: 0.8436\n",
      "Epoch 8/30, Loss: 0.7241\n",
      "Epoch 9/30, Loss: 0.6983\n",
      "Epoch 10/30, Loss: 0.5625\n",
      "Epoch 11/30, Loss: 0.5134\n",
      "Epoch 12/30, Loss: 0.4365\n",
      "Epoch 13/30, Loss: 0.4915\n",
      "Epoch 14/30, Loss: 0.3823\n",
      "Epoch 15/30, Loss: 0.9297\n",
      "Epoch 16/30, Loss: 0.6008\n",
      "Epoch 17/30, Loss: 0.4782\n",
      "Epoch 18/30, Loss: 0.4586\n",
      "Epoch 19/30, Loss: 0.5067\n",
      "Epoch 20/30, Loss: 0.3740\n",
      "Epoch 21/30, Loss: 0.2966\n",
      "Epoch 22/30, Loss: 0.3019\n",
      "Epoch 23/30, Loss: 0.2526\n",
      "Epoch 24/30, Loss: 0.2369\n",
      "Epoch 25/30, Loss: 0.2624\n",
      "Epoch 26/30, Loss: 0.3409\n",
      "Epoch 27/30, Loss: 0.1867\n",
      "Epoch 28/30, Loss: 0.2136\n",
      "Epoch 29/30, Loss: 0.1682\n",
      "Epoch 30/30, Loss: 0.1811\n",
      "Accuracy: 0.9754\n",
      "Classification Report:\n",
      "                              precision    recall  f1-score   support\n",
      "\n",
      "            can_you_help_me       0.95      1.00      0.98        21\n",
      "              doesnt_matter       0.87      1.00      0.93        26\n",
      "                   good_bey       0.95      0.95      0.95        20\n",
      "               i_have_to_go       1.00      0.92      0.96        26\n",
      "      i_think_you_are_wrong       1.00      0.96      0.98        25\n",
      "            sorry_cant_stay       1.00      0.88      0.94        26\n",
      "       sorry_for_being_late       0.83      0.94      0.88        16\n",
      "               speak_slowly       1.00      0.91      0.95        23\n",
      "    thanks_for_your_concern       1.00      1.00      1.00        18\n",
      "      wish_you_luck_in_work       0.92      0.92      0.92        12\n",
      "      wish_you_good_journey       1.00      0.96      0.98        25\n",
      "     wish_you_good_vacation       1.00      1.00      1.00        23\n",
      "             please_quickly       1.00      1.00      1.00        19\n",
      "              explain_again       1.00      1.00      1.00        19\n",
      "               repeat_again       1.00      1.00      1.00        21\n",
      "               free_or_busy       1.00      1.00      1.00        20\n",
      "          happy_to_know_you       1.00      1.00      1.00        21\n",
      "                 i_disagree       1.00      1.00      1.00        19\n",
      "                    i_agree       1.00      1.00      1.00        12\n",
      "   i_would_like_to_meet_you       0.96      1.00      0.98        27\n",
      "                any_service       1.00      1.00      1.00        21\n",
      "               come_quickly       1.00      1.00      1.00        15\n",
      "             happy_new_year       1.00      1.00      1.00        20\n",
      "         how_can_i_call_you       0.95      0.95      0.95        19\n",
      "                wait_please       0.91      0.95      0.93        21\n",
      "               lets_go_swim       1.00      0.93      0.97        15\n",
      "            whats_your_name       0.96      1.00      0.98        22\n",
      "what_about_going_for_a_walk       1.00      1.00      1.00        22\n",
      "               unbelievable       1.00      1.00      1.00        24\n",
      "  can_i_take_from_your_time       1.00      1.00      1.00        11\n",
      "\n",
      "                   accuracy                           0.98       609\n",
      "                  macro avg       0.98      0.98      0.98       609\n",
      "               weighted avg       0.98      0.98      0.98       609\n",
      "\n",
      "Confusion Matrix:\n",
      " [[21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0 26  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  1 19  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  1  0 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   1  0  0  0  0  0]\n",
      " [ 0  0  1  0 24  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 23  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0 15  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 18  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0 11  0  0  0  0  0  0  0  0  0  1  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 24  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  1  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0 23  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 19  0  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 12  0  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 27  0  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 21  0  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 15  0  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 20  0\n",
      "   0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 18\n",
      "   1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  1\n",
      "  20  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0 14  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0 22  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0 22  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0 24  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "   0  0  0  0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "# Define model parameters\n",
    "input_dim = 258  # Number of features per frame\n",
    "hidden_dim = 512  # Hidden layer size\n",
    "num_classes = len(actions)  # Number of unique actions (classes)\n",
    "\n",
    "# Initialize the model\n",
    "model = EnhancedRNNBiLSTMModel(input_dim=input_dim, hidden_dim=hidden_dim, num_classes=num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training function\n",
    "def train_model(model, dataloader, criterion, optimizer, epochs=30):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    "        \n",
    "        avg_loss = total_loss / len(dataloader)\n",
    "        print(f'Epoch {epoch + 1}/{epochs}, Loss: {avg_loss:.4f}')\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, criterion, optimizer)\n",
    "\n",
    "# Evaluation function\n",
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    class_report = classification_report(all_labels, all_preds, target_names=actions)\n",
    "    conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"Classification Report:\\n\", class_report)\n",
    "    print(\"Confusion Matrix:\\n\", conf_matrix)\n",
    "\n",
    "# Evaluate the model using the test DataLoader\n",
    "evaluate_model(model, test_loader)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CrossEntropyLoss: A loss function used for multi-class classification problems.\n",
    "AdamW: An optimizer that adjusts the learning rate dynamically to improve training performance.##################################################################################################\n",
    "1-train_model: This function handles the model training process. It performs the forward pass, 2-computes the loss, and updates the model weights using backpropagation.\n",
    "3-zero_grad: Clears old gradients, which are accumulated during training.\n",
    "4-loss.backward: Computes gradients of the loss.\n",
    "5-optimizer.step: Updates the model weights.\n",
    "##################################################################################################\n",
    "evaluate_model: This function evaluates the trained model on the test data. It computes the model’s predictions, calculates accuracy, and provides a classification report and confusion matrix to assess performance.\n",
    "torch.no_grad(): Disables gradient calculations, which speeds up the evaluation process and reduces memory consumption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NEWAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
